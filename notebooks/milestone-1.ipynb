{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bd12f3d-1806-4c9f-b3af-e234b2296e49",
   "metadata": {},
   "source": [
    "# DSCI 525 Group 4 - Data retrieval using figshare API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3c0811-60f0-45b9-a5b8-c8a11383cb0e",
   "metadata": {},
   "source": [
    "## Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ff37e05-879d-4ce7-9f98-20107f88df53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import zipfile\n",
    "import requests\n",
    "from urllib.request import urlretrieve\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea3d470-c509-47b0-951e-eca2e976fd1a",
   "metadata": {},
   "source": [
    "## Specify Meta variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "298f9fa5-96c4-492a-ab9b-2965c5b1244f",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_id = 14096681\n",
    "url = f\"https://api.figshare.com/v2/articles/{article_id}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "output_directory = \"..\\data\"\n",
    "file_to_download = \"data.zip\"\n",
    "rerun = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993388f2-00b3-4873-bb39-0709c1ae5082",
   "metadata": {},
   "source": [
    "## List of files available for download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c74834df-1442-4e91-812e-e9aa48294127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 0:00:45.950148.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 26579150,\n",
       "  'name': 'daily_rainfall_2014.png',\n",
       "  'size': 58863,\n",
       "  'is_link_only': False,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26579150',\n",
       "  'supplied_md5': 'fd32a2ffde300a31f8d63b1825d47e5e',\n",
       "  'computed_md5': 'fd32a2ffde300a31f8d63b1825d47e5e'},\n",
       " {'id': 26579171,\n",
       "  'name': 'environment.yml',\n",
       "  'size': 192,\n",
       "  'is_link_only': False,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26579171',\n",
       "  'supplied_md5': '060b2020017eed93a1ee7dd8c65b2f34',\n",
       "  'computed_md5': '060b2020017eed93a1ee7dd8c65b2f34'},\n",
       " {'id': 26586554,\n",
       "  'name': 'README.md',\n",
       "  'size': 5422,\n",
       "  'is_link_only': False,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26586554',\n",
       "  'supplied_md5': '61858c6cc0e6a6d6663a7e4c75bbd88c',\n",
       "  'computed_md5': '61858c6cc0e6a6d6663a7e4c75bbd88c'},\n",
       " {'id': 26766812,\n",
       "  'name': 'data.zip',\n",
       "  'size': 814041183,\n",
       "  'is_link_only': False,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26766812',\n",
       "  'supplied_md5': 'b517383f76e77bd03755a63a8ff83ee9',\n",
       "  'computed_md5': 'b517383f76e77bd03755a63a8ff83ee9'},\n",
       " {'id': 26766815,\n",
       "  'name': 'get_data.py',\n",
       "  'size': 4113,\n",
       "  'is_link_only': False,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26766815',\n",
       "  'supplied_md5': '7829028495fd9dec9680ea013474afa6',\n",
       "  'computed_md5': '7829028495fd9dec9680ea013474afa6'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "data = json.loads(response.text)\n",
    "files = data[\"files\"]\n",
    "print(f\"Run time: {str(datetime.timedelta(minutes=timeit.default_timer()-start))}.\")\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f2eb6b-0370-4931-b480-7ae41a43f52e",
   "metadata": {},
   "source": [
    "## Download specified file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f091669-0b3b-45d9-b908-74c061b15915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.zip is already exists!\n",
      "Run time: 0:00:00.\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "if os.path.exists(f\"{output_directory}\\\\{file_to_download}\"):\n",
    "    print(\"data.zip is already exists!\")\n",
    "else:\n",
    "    files_to_dl = [\"data.zip\"]\n",
    "\n",
    "    for file in files:\n",
    "        if file[\"name\"] in files_to_dl:\n",
    "            os.makedirs(output_directory, exist_ok=True)\n",
    "            urlretrieve(file[\"download_url\"], os.path.join(output_directory, file[\"name\"]))\n",
    "print(f\"Run time: {str(datetime.timedelta(minutes=int(timeit.default_timer()-start)))}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7b63cb-02ab-41e0-b251-d56d354029b3",
   "metadata": {},
   "source": [
    "## Unzip downloaded file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8aec9bac-eed7-48e1-af18-95d16fc87b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 0:15:00.\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "if rerun:\n",
    "    with zipfile.ZipFile(os.path.join(output_directory, file_to_download), 'r') as f:\n",
    "        f.extractall(output_directory)\n",
    "else:\n",
    "    print(\"Some CSV files already exists, nothing is extraced. Please check if files in data directory are correct.\")\n",
    "print(f\"Run time: {str(datetime.timedelta(minutes=int(timeit.default_timer()-start)))}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c182bcc8-2439-400d-8520-8dec8c4fe1da",
   "metadata": {},
   "source": [
    "## 4. Combining data CSVs\n",
    "rubric={correctness:10,reasoning:10}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd08b73f-d45d-4c57-8174-f20a161a430c",
   "metadata": {},
   "source": [
    "1. Combine data CSVs into a single CSV using pandas.\n",
    "\n",
    "2. When combining the CSV files, add an extra column called \"model\" that identifies the model. Tip 1: you can get this column populated from the file name, eg: for file name \"SAM0-UNICON_daily_rainfall_NSW.csv\", the model name is SAM0-UNICON Tip 2: Remember how we added year when we combined airline CSVs. Tip 3: You can use regex generator.\n",
    "\n",
    "Note: There is a file called observed_daily_rainfall_SYD.csv in the data folder that you downloaded. Make sure you exclude this file (programmatically or just take out that file from folder) before you combine CSVs. We will use this file in our next milestone.\n",
    "\n",
    "3. Compare run times on different machines within your team and summarize your observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1259ca2-dd56-40b8-9f91-d36fb9855201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ..\\data\\ACCESS-CM2_daily_rainfall_NSW.csv                    total 1932840 rows,                   1 out of 27 files.\n",
      "Processing ..\\data\\ACCESS-ESM1-5_daily_rainfall_NSW.csv                 total 1610700 rows,                   2 out of 27 files.\n",
      "Processing ..\\data\\AWI-ESM-1-1-LR_daily_rainfall_NSW.csv                total 966420 rows,                   3 out of 27 files.\n",
      "Processing ..\\data\\BCC-CSM2-MR_daily_rainfall_NSW.csv                   total 3035340 rows,                   4 out of 27 files.\n",
      "Processing ..\\data\\BCC-ESM1_daily_rainfall_NSW.csv                      total 551880 rows,                   5 out of 27 files.\n",
      "Processing ..\\data\\CanESM5_daily_rainfall_NSW.csv                       total 551880 rows,                   6 out of 27 files.\n",
      "Processing ..\\data\\CMCC-CM2-HR4_daily_rainfall_NSW.csv                  total 3541230 rows,                   7 out of 27 files.\n",
      "Processing ..\\data\\CMCC-CM2-SR5_daily_rainfall_NSW.csv                  total 3541230 rows,                   8 out of 27 files.\n",
      "Processing ..\\data\\CMCC-ESM2_daily_rainfall_NSW.csv                     total 3541230 rows,                   9 out of 27 files.\n",
      "Processing ..\\data\\EC-Earth3-Veg-LR_daily_rainfall_NSW.csv              total 3037320 rows,                   10 out of 27 files.\n",
      "Processing ..\\data\\FGOALS-f3-L_daily_rainfall_NSW.csv                   total 3219300 rows,                   11 out of 27 files.\n",
      "Processing ..\\data\\FGOALS-g3_daily_rainfall_NSW.csv                     total 1287720 rows,                   12 out of 27 files.\n",
      "Processing ..\\data\\GFDL-CM4_daily_rainfall_NSW.csv                      total 3219300 rows,                   13 out of 27 files.\n",
      "Processing ..\\data\\GFDL-ESM4_daily_rainfall_NSW.csv                     total 3219300 rows,                   14 out of 27 files.\n",
      "Processing ..\\data\\INM-CM4-8_daily_rainfall_NSW.csv                     total 1609650 rows,                   15 out of 27 files.\n",
      "Processing ..\\data\\INM-CM5-0_daily_rainfall_NSW.csv                     total 1609650 rows,                   16 out of 27 files.\n",
      "Processing ..\\data\\KIOST-ESM_daily_rainfall_NSW.csv                     total 1287720 rows,                   17 out of 27 files.\n",
      "Processing ..\\data\\MIROC6_daily_rainfall_NSW.csv                        total 2070900 rows,                   18 out of 27 files.\n",
      "Processing ..\\data\\MPI-ESM-1-2-HAM_daily_rainfall_NSW.csv               total 966420 rows,                   19 out of 27 files.\n",
      "Processing ..\\data\\MPI-ESM1-2-HR_daily_rainfall_NSW.csv                 total 5154240 rows,                   20 out of 27 files.\n",
      "Processing ..\\data\\MPI-ESM1-2-LR_daily_rainfall_NSW.csv                 total 966420 rows,                   21 out of 27 files.\n",
      "Processing ..\\data\\MRI-ESM2-0_daily_rainfall_NSW.csv                    total 3037320 rows,                   22 out of 27 files.\n",
      "Processing ..\\data\\NESM3_daily_rainfall_NSW.csv                         total 966420 rows,                   23 out of 27 files.\n",
      "Processing ..\\data\\NorESM2-LM_daily_rainfall_NSW.csv                    total 919800 rows,                   24 out of 27 files.\n",
      "Processing ..\\data\\NorESM2-MM_daily_rainfall_NSW.csv                    total 3541230 rows,                   25 out of 27 files.\n",
      "Processing ..\\data\\SAM0-UNICON_daily_rainfall_NSW.csv                   total 3541153 rows,                   26 out of 27 files.\n",
      "Processing ..\\data\\TaiESM1_daily_rainfall_NSW.csv                       total 3541230 rows,                   27 out of 27 files.\n",
      "\n",
      "Total rows: 62467843.\n",
      "\n",
      "Run time: 6:34:00.\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "if rerun:\n",
    "    files = glob.glob(f'{output_directory}/*.csv')\n",
    "    files = [f for f in files if f.find(\"observed_daily_rainfall_SYD.csv\")==-1 and f.find(\"combined_data.csv\")==-1]\n",
    "    \n",
    "    if len(files) != 27:\n",
    "        print(\"Expected 27 files.\")\n",
    "        \n",
    "    i = 1\n",
    "    records = 0\n",
    "\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file, index_col=0, parse_dates=True).assign(model=re.findall(r'[^\\/&\\\\]+(?=_daily_rainfall_NSW\\.)', file)[0])\n",
    "        print(f\"Processing {file:<60} total {len(df)}{' rows, ':<25}{i} out of {len(files)} files.\")\n",
    "        records += len(df)\n",
    "\n",
    "        if i == 1:\n",
    "            df.to_csv(f\"{output_directory}/combined_data.csv\")\n",
    "        else:\n",
    "            df.to_csv(f'{output_directory}/combined_data.csv', mode='a', header=False)\n",
    "\n",
    "        i+=1\n",
    "    print(\"\")\n",
    "    print(f\"Total rows: {records}.\") #62467843 rows\n",
    "    print(\"\")\n",
    "print(f\"Run time: {str(datetime.timedelta(minutes=int(timeit.default_timer()-start)))}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78d7038-bd7e-4d56-be70-85bc26e5c4a5",
   "metadata": {},
   "source": [
    "## Compare results:\n",
    "\n",
    "| Team Member          | Operating System | RAM (GB) | Processor                 | Is SSD | Time taken |\n",
    "| -------------------- | ---------------- | -------- | ------------------------- | ------ | ---------- |\n",
    "| Anahita Einolghozati | MacBook Pro| 8 | M1 | Yes| 7min 25s |\n",
    "| Luke Collins         | Windows 11 x64 | 16 | 11th Gen Intel i7 2.80 GHz | Yes | 10min 26s |\n",
    "| Zihan Zhou           | MacBook Pro  |  8 | M1 | Yes | 7min 22s |\n",
    "| Steven Lio           | Windows 10 x64   | 16     | AMD Ryzen 7 5800H 3.20GHz | Yes    | 6 mins 34s |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "766a3ac6-fa24-4ac3-9068-7943a49c4df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.7G\t../data/combined_data.csv\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "du -sh \"../data/combined_data.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d30f15d-baa0-4797-bb39-76ad5ab7cc8e",
   "metadata": {},
   "source": [
    "## 5. Load the combined CSV to memory and perform a simple EDA\n",
    "rubric={correctness:10,reasoning:10}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd06729-bb8b-4433-8ddd-349e09a246ef",
   "metadata": {},
   "source": [
    "1. Investigate at least two of the following approaches to reduce memory usage while performing the EDA (e.g., value_counts).\n",
    "\n",
    "- Changing dtype of your data\n",
    "- Load just columns what we want\n",
    "- Loading in chunks\n",
    "- Dask\n",
    "2. Compare run times on different machines within your team and summarize your observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628b04ed-4b5e-4b94-b7d0-72ed6926dcb2",
   "metadata": {},
   "source": [
    "## Benchmark: Load everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dea8609-8c57-4dcb-8dba-7da77423cc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "\n",
      "MPI-ESM1-2-HR       5154240\n",
      "TaiESM1             3541230\n",
      "NorESM2-MM          3541230\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-ESM2           3541230\n",
      "SAM0-UNICON         3541153\n",
      "FGOALS-f3-L         3219300\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "MRI-ESM2-0          3037320\n",
      "BCC-CSM2-MR         3035340\n",
      "MIROC6              2070900\n",
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "INM-CM5-0           1609650\n",
      "INM-CM4-8           1609650\n",
      "KIOST-ESM           1287720\n",
      "FGOALS-g3           1287720\n",
      "MPI-ESM1-2-LR        966420\n",
      "NESM3                966420\n",
      "AWI-ESM-1-1-LR       966420\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "NorESM2-LM           919800\n",
      "BCC-ESM1             551880\n",
      "CanESM5              551880\n",
      "Name: model, dtype: int64\n",
      "--------------------------------------------------\n",
      "Run time: 1:31:00.\n",
      "The size of df in memory: 6.72 GB.\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "df = pd.read_csv(f\"{output_directory}/combined_data.csv\", index_col=0, parse_dates=True)\n",
    "print(\"Output:\")\n",
    "print(\"\")\n",
    "print(df[\"model\"].value_counts())\n",
    "print(\"-\"*50)\n",
    "print(f\"Run time: {str(datetime.timedelta(minutes=int(timeit.default_timer()-start)))}.\")\n",
    "print(f\"The size of df in memory: {round(sys.getsizeof(df) / (1024 * 1024 * 1024), 2)} GB.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9b0157-c654-4a05-bf6f-9d3a889b1f73",
   "metadata": {},
   "source": [
    "## Compare results:\n",
    "\n",
    "| Team Member          | Operating System | RAM (GB) | Processor                 | Is SSD | Time taken |\n",
    "| -------------------- | ---------------- | -------- | ------------------------- | ------ | ---------- |\n",
    "| Anahita Einolghozati | MacBook Pro| 8 | M1 | Yes| 1min 15s |\n",
    "| Luke Collins         | Windows 11 x64 | 16 | 11th Gen Intel i7 2.80 GHz | Yes | 2min 59s |\n",
    "| Zihan Zhou           | MacBook Pro  |  8 | M1 | Yes |1min 30s |\n",
    "| Steven Lio           | Windows 10 x64   | 16     | AMD Ryzen 7 5800H 3.20GHz | Yes    | 1 mins 31s |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ded4fb-4284-4ca7-8ebe-701ccb29822e",
   "metadata": {},
   "source": [
    "## Change dtype of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92044da3-6a27-47f4-b9b1-81de867366d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "\n",
      "MPI-ESM1-2-HR       5154240\n",
      "TaiESM1             3541230\n",
      "NorESM2-MM          3541230\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-ESM2           3541230\n",
      "SAM0-UNICON         3541153\n",
      "FGOALS-f3-L         3219300\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "MRI-ESM2-0          3037320\n",
      "BCC-CSM2-MR         3035340\n",
      "MIROC6              2070900\n",
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "INM-CM5-0           1609650\n",
      "INM-CM4-8           1609650\n",
      "KIOST-ESM           1287720\n",
      "FGOALS-g3           1287720\n",
      "MPI-ESM1-2-LR        966420\n",
      "NESM3                966420\n",
      "AWI-ESM-1-1-LR       966420\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "NorESM2-LM           919800\n",
      "BCC-ESM1             551880\n",
      "CanESM5              551880\n",
      "Name: model, dtype: int64\n",
      "--------------------------------------------------\n",
      "Run time: 1:27:00.\n",
      "The size of df in memory: 5.09 GB.\n",
      "\n",
      "Column types:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "lat_min          float16\n",
       "lat_max          float16\n",
       "lon_min          float16\n",
       "lon_max          float16\n",
       "rain (mm/day)    float32\n",
       "model             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "dtypes = {'lat_min': 'float16', \n",
    "          'lat_max': 'float16', \n",
    "          'lon_min': 'float16', \n",
    "          'lon_max': 'float16',\n",
    "          'rain (mm/day)':'float32',\n",
    "          'model':'str'}\n",
    "df = pd.read_csv(f\"{output_directory}/combined_data.csv\",index_col=0, parse_dates=True, dtype=dtypes)\n",
    "print(\"Output:\")\n",
    "print(\"\")\n",
    "print(df[\"model\"].value_counts())\n",
    "print(\"-\"*50)\n",
    "print(f\"Run time: {str(datetime.timedelta(minutes=int(timeit.default_timer()-start)))}.\")\n",
    "print(f\"The size of df in memory: {round(sys.getsizeof(df) / (1024 * 1024 * 1024), 2)} GB.\")\n",
    "print(\"\")\n",
    "print(f\"Column types:\")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0ec15b-ffbe-40a8-af70-e36dcb35fff1",
   "metadata": {},
   "source": [
    "## Compare results:\n",
    "\n",
    "| Team Member          | Operating System | RAM (GB) | Processor                 | Is SSD | Time taken |\n",
    "| -------------------- | ---------------- | -------- | ------------------------- | ------ | ---------- |\n",
    "| Anahita Einolghozati | MacBook Pro| 8 | M1 | Yes| 1min 12s |\n",
    "| Luke Collins         | Windows 11 x64 | 16 | 11th Gen Intel i7 2.80 GHz | Yes | 2min 7s |\n",
    "| Zihan Zhou           | MacBook Pro  |  8 | M1 | Yes | 1min 35s |\n",
    "| Steven Lio           | Windows 10 x64   | 16     | AMD Ryzen 7 5800H 3.20GHz | Yes    | 1 mins 27s |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06874d0-9911-4462-9dad-7ed076d14d6f",
   "metadata": {},
   "source": [
    "## Load only minimum columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7cc9b4e-969b-4208-881e-f1cca660bc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "\n",
      "MPI-ESM1-2-HR       5154240\n",
      "TaiESM1             3541230\n",
      "NorESM2-MM          3541230\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-ESM2           3541230\n",
      "SAM0-UNICON         3541153\n",
      "FGOALS-f3-L         3219300\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "MRI-ESM2-0          3037320\n",
      "BCC-CSM2-MR         3035340\n",
      "MIROC6              2070900\n",
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "INM-CM5-0           1609650\n",
      "INM-CM4-8           1609650\n",
      "KIOST-ESM           1287720\n",
      "FGOALS-g3           1287720\n",
      "MPI-ESM1-2-LR        966420\n",
      "NESM3                966420\n",
      "AWI-ESM-1-1-LR       966420\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "NorESM2-LM           919800\n",
      "BCC-ESM1             551880\n",
      "CanESM5              551880\n",
      "Name: model, dtype: int64\n",
      "--------------------------------------------------\n",
      "Run time: 1:16:00.\n",
      "The size of df in memory: 4.86 GB.\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "use_cols = [\"time\",\"rain (mm/day)\",\"model\"]\n",
    "df = pd.read_csv(f\"{output_directory}/combined_data.csv\",index_col=0, parse_dates=True, usecols=use_cols)\n",
    "print(\"Output:\")\n",
    "print(\"\")\n",
    "print(df[\"model\"].value_counts())\n",
    "print(\"-\"*50)\n",
    "print(f\"Run time: {str(datetime.timedelta(minutes=int(timeit.default_timer()-start)))}.\")\n",
    "print(f\"The size of df in memory: {round(sys.getsizeof(df) / (1024 * 1024 * 1024), 2)} GB.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b53bd28-331a-4280-96e2-030a0c35a38b",
   "metadata": {},
   "source": [
    "## Compare results:\n",
    "\n",
    "| Team Member          | Operating System | RAM (GB) | Processor                 | Is SSD | Time taken |\n",
    "| -------------------- | ---------------- | -------- | ------------------------- | ------ | ---------- |\n",
    "| Anahita Einolghozati | MacBook Pro| 8 | M1 | Yes| 1min 5s |\n",
    "| Luke Collins         | Windows 11 x64 | 16 | 11th Gen Intel i7 2.80 GHz | Yes | 1min 32s |\n",
    "| Zihan Zhou           | MacBook Pro  |  8 | M1 | Yes |1min 23s|\n",
    "| Steven Lio           | Windows 10 x64   | 16     | AMD Ryzen 7 5800H 3.20GHz | Yes    | 1 mins 16s |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da027b8d-8662-40c7-a4d6-f0a48e365956",
   "metadata": {},
   "source": [
    "## Load only minimum columns and specify column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2943b0dd-1cbd-4f91-a408-37670a450efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "\n",
      "MPI-ESM1-2-HR       5154240\n",
      "TaiESM1             3541230\n",
      "NorESM2-MM          3541230\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-ESM2           3541230\n",
      "SAM0-UNICON         3541153\n",
      "FGOALS-f3-L         3219300\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "MRI-ESM2-0          3037320\n",
      "BCC-CSM2-MR         3035340\n",
      "MIROC6              2070900\n",
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "INM-CM5-0           1609650\n",
      "INM-CM4-8           1609650\n",
      "KIOST-ESM           1287720\n",
      "FGOALS-g3           1287720\n",
      "MPI-ESM1-2-LR        966420\n",
      "NESM3                966420\n",
      "AWI-ESM-1-1-LR       966420\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "NorESM2-LM           919800\n",
      "BCC-ESM1             551880\n",
      "CanESM5              551880\n",
      "Name: model, dtype: int64\n",
      "--------------------------------------------------\n",
      "Run time: 1:16:00.\n",
      "The size of df in memory: 4.62 GB.\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "use_cols = [\"time\",\"rain (mm/day)\",\"model\"]\n",
    "dtypes = {'rain (mm/day)':'float32',\n",
    "          'model':'str'}\n",
    "df = pd.read_csv(f\"{output_directory}/combined_data.csv\",index_col=0, parse_dates=True, usecols=use_cols,dtype=dtypes)\n",
    "print(\"Output:\")\n",
    "print(\"\")\n",
    "print(df[\"model\"].value_counts())\n",
    "print(\"-\"*50)\n",
    "print(f\"Run time: {str(datetime.timedelta(minutes=int(timeit.default_timer()-start)))}.\")\n",
    "print(f\"The size of df in memory: {round(sys.getsizeof(df) / (1024 * 1024 * 1024), 2)} GB.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8515708-143a-4c30-83c6-ac82bb7352d8",
   "metadata": {},
   "source": [
    "## Compare results:\n",
    "\n",
    "| Team Member          | Operating System | RAM (GB) | Processor                 | Is SSD | Time taken |\n",
    "| -------------------- | ---------------- | -------- | ------------------------- | ------ | ---------- |\n",
    "| Anahita Einolghozati | MacBook Pro| 8 | M1 | Yes| 1min 22s |\n",
    "| Luke Collins         | Windows 11 x64 | 16 | 11th Gen Intel i7 2.80 GHz | Yes | 1min 51s |\n",
    "| Zihan Zhou           | MacBook Pro  |  8 | M1 | Yes | 1min 22s |\n",
    "| Steven Lio           | Windows 10 x64   | 16     | AMD Ryzen 7 5800H 3.20GHz | Yes    | 1 mins 16s |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdaacae-07ab-46ec-b51b-9c06b2a75fc1",
   "metadata": {},
   "source": [
    "## Loading in chunks (1 million rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ebbca27-3962-4f5f-a319-54c074c33eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "\n",
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "AWI-ESM-1-1-LR       966420\n",
      "BCC-CSM2-MR         3035340\n",
      "BCC-ESM1             551880\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-ESM2           3541230\n",
      "CanESM5              551880\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "FGOALS-f3-L         3219300\n",
      "FGOALS-g3           1287720\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "INM-CM4-8           1609650\n",
      "INM-CM5-0           1609650\n",
      "KIOST-ESM           1287720\n",
      "MIROC6              2070900\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "MPI-ESM1-2-HR       5154240\n",
      "MPI-ESM1-2-LR        966420\n",
      "MRI-ESM2-0          3037320\n",
      "NESM3                966420\n",
      "NorESM2-LM           919800\n",
      "NorESM2-MM          3541230\n",
      "SAM0-UNICON         3541153\n",
      "TaiESM1             3541230\n",
      "dtype: int32\n",
      "--------------------------------------------------\n",
      "Run time: 0:57:00.\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "counts = pd.Series(dtype=int)\n",
    "\n",
    "df = pd.read_csv(f\"{output_directory}/combined_data.csv\", chunksize=1_000_000 )\n",
    "\n",
    "for chunk in pd.read_csv(f\"{output_directory}/combined_data.csv\", chunksize=1_000_000):\n",
    "    counts = counts.add(chunk[\"model\"].value_counts(), fill_value=0)\n",
    "\n",
    "print(\"Output:\")\n",
    "print(\"\")\n",
    "print(counts.astype(int))\n",
    "print(\"-\"*50)\n",
    "print(f\"Run time: {str(datetime.timedelta(minutes=int(timeit.default_timer()-start)))}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f8750f-d4e6-4f35-97fb-50e8430ded31",
   "metadata": {},
   "source": [
    "## Compare results:\n",
    "\n",
    "| Team Member          | Operating System | RAM (GB) | Processor                 | Is SSD | Time taken |\n",
    "| -------------------- | ---------------- | -------- | ------------------------- | ------ | ---------- |\n",
    "| Anahita Einolghozati | MacBook Pro| 8 | M1 | Yes| 48.9s |\n",
    "| Luke Collins         | Windows 11 x64 | 16 | 11th Gen Intel i7 2.80 GHz | Yes | 1min 21s |\n",
    "| Zihan Zhou           | MacBook Pro  |  8 | M1 | Yes | 1min 11s |\n",
    "| Steven Lio           | Windows 10 x64   | 16     | AMD Ryzen 7 5800H 3.20GHz | Yes    | 57s        |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30354c90-b358-4552-a947-f859a27cd09c",
   "metadata": {},
   "source": [
    "# Dicussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db337482-d5bf-473e-85b1-6d1361f35b63",
   "metadata": {},
   "source": [
    "Compares to native pandas csv import:\n",
    "\n",
    "Change dtype of data:\n",
    "- Pros: reduce size in memory after reading\n",
    "- Cons: best data type is not usually known ahead of time\n",
    "\n",
    "Load only minimum columns:\n",
    "- Pros: faster import and reduce size in memory after reading\n",
    "- Cons: if new column is needed the file has to be import again\n",
    "\n",
    "Load only minimum columns & specify dtype:\n",
    "- Pros: faster import and further reduce size in memory after reading\n",
    "- Cons: if new column is needed the file has to be import again and best data type is not usually known ahead of time\n",
    "\n",
    "Loading in chunks:\n",
    "- Pros: fastest in import and uses much less memory if the chunks are not being told to store in memory\n",
    "- Cons: only usable if program can work with chunks of data (say if we do mapping of data points then chunks won't work)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0dad3c-7fc8-4933-8a74-2ee7f160a881",
   "metadata": {},
   "source": [
    "## Compare dataframe transfer from Python to R for EDA using Parquet file format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3fcd39-d0e9-4ce3-9df8-ae1f8855c19f",
   "metadata": {},
   "source": [
    "Import full dataframe to Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4b41bed-4288-45f9-9e1b-4c359acd9c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "if rerun:\n",
    "    df = pd.read_csv(f\"{output_directory}/combined_data.csv\",index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4738b53-f177-497f-9f8e-c3b70ae2edc5",
   "metadata": {},
   "source": [
    "Convert data file into parquet format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc7391e8-d9af-4877-95df-785deef59c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 0:14:00.\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "if rerun:\n",
    "    df.to_parquet(f\"{output_directory}/combined_data.parquet\")\n",
    "print(f\"Run time: {str(datetime.timedelta(minutes=int(timeit.default_timer()-start)))}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a5698f-8de1-4079-b9fe-0724f0d474e8",
   "metadata": {},
   "source": [
    "Convert data file into parquet format (with partition by model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82326dbf-8d5f-4b22-b3f4-b9baa71d9500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 0:23:00.\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "if rerun:\n",
    "    df.to_parquet(f\"{output_directory}/combined_data_partition.parquet\",partition_cols=['model'])\n",
    "print(f\"Run time: {str(datetime.timedelta(minutes=int(timeit.default_timer()-start)))}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38402593-9a45-4b02-89fd-4f9ad7a33cf4",
   "metadata": {},
   "source": [
    "Compare storage size in drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4173586f-8711-4441-b4ca-bc8b755af82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.7G\t../data/combined_data.csv\n",
      "542M\t../data/combined_data.parquet\n",
      "550M\t../data/combined_data_partition.parquet\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "du -sh \"../data/combined_data.csv\"\n",
    "du -sh \"../data/combined_data.parquet\"\n",
    "du -sh \"../data/combined_data_partition.parquet\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7d0f05-4fbd-4d18-883e-f9bb3bbd1c33",
   "metadata": {},
   "source": [
    "Import parquet file to Python and row count by model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c6e718d-3345-4195-9f2b-384e8a9930b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "\n",
      "MPI-ESM1-2-HR       5154240\n",
      "TaiESM1             3541230\n",
      "NorESM2-MM          3541230\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-ESM2           3541230\n",
      "SAM0-UNICON         3541153\n",
      "FGOALS-f3-L         3219300\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "MRI-ESM2-0          3037320\n",
      "BCC-CSM2-MR         3035340\n",
      "MIROC6              2070900\n",
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "INM-CM5-0           1609650\n",
      "INM-CM4-8           1609650\n",
      "KIOST-ESM           1287720\n",
      "FGOALS-g3           1287720\n",
      "MPI-ESM1-2-LR        966420\n",
      "NESM3                966420\n",
      "AWI-ESM-1-1-LR       966420\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "NorESM2-LM           919800\n",
      "BCC-ESM1             551880\n",
      "CanESM5              551880\n",
      "Name: model, dtype: int64\n",
      "--------------------------------------------------\n",
      "Run time: 0:08:00.\n",
      "The size of df in memory: 6.72 GB.\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "df = pd.read_parquet(f\"{output_directory}/combined_data.parquet\")\n",
    "print(\"Output:\")\n",
    "print(\"\")\n",
    "print(df[\"model\"].value_counts())\n",
    "print(\"-\"*50)\n",
    "print(f\"Run time: {str(datetime.timedelta(minutes=int(timeit.default_timer()-start)))}.\")\n",
    "print(f\"The size of df in memory: {round(sys.getsizeof(df) / (1024 * 1024 * 1024), 2)} GB.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a029aa-e347-4e93-8b02-4096644051ab",
   "metadata": {},
   "source": [
    "Import into R and row count by model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "509beaed-8247-4304-a660-46b23ac26bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kpgha\\.conda\\envs\\525_2022\\lib\\site-packages\\rpy2\\robjects\\packages.py:366: UserWarning: The symbol 'quartz' is not in this R namespace/package.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7349a42f-64c3-46f5-a10e-d5d7a96ced79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time difference of 1.867574 secs\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "suppressPackageStartupMessages(library(dplyr,quietly=TRUE))\n",
    "\n",
    "start <- Sys.time()\n",
    "output_directory <- \"../data\"\n",
    "#df <- arrow::open_dataset(paste0(output_directory,\"/\",\"combined_data.parquet\"))\n",
    "df <- arrow::open_dataset(paste0(output_directory,\"/\",\"combined_data_partition.parquet\"), \n",
    "                          format=\"parquet\", \n",
    "                          partitioning=c(\"model\"))\n",
    "df %>%\n",
    "    group_by(model) %>%\n",
    "    summarize(cnt=n()) %>%\n",
    "    ungroup() %>%\n",
    "    collect()\n",
    "\n",
    "Sys.time() - start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be67519-e0fc-4ff5-80b9-cf956433f1e7",
   "metadata": {},
   "source": [
    "R is much more impressive in opening parquet file than Python in terms of I/O speed. (1.9s vs 8s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60b327f-50bd-41b1-8d3c-e8d328d70cbf",
   "metadata": {},
   "source": [
    "## Discussion:\n",
    "\n",
    "Our team explored all 4 dataframe transfer methods and we picked `parquet` for this following reasons:\n",
    "- The implementation of converting to `parquet` is already provided in pandas. \n",
    "- Although `feather` is also supported by pandas but `parquet` has the better compression than `feather` where the storage memory for `parquet` of this data set is almost half of `feather`. \n",
    "- We found that pandas' implementation converting to `feather` does not support pandas dataframe with a datetime index which we have in this case, where `parquet` does not care about the datetime index as much, although it did took slightly longer time to write into `parquet` format.\n",
    "- `parquet` has best support in terms of data partitioning, also it can have much faster read when subset of the columns, data were selected given the projection and predicate pushdown capabilities provided by the arrow engine\n",
    "- `feather` was design to transfer data between Python and R but we also consider `parquet` is better for long term storage (perfect for historical data like this one) and we found no significant time differences between these two file types.\n",
    "\n",
    "We also looked at:\n",
    "- Pandas Exchange: was not able to complete since the conversion took too much memory (RAM) and we were unable to run.\n",
    "- Pyarrow: we found no easy way for R to read in a arrow file type direct from drive and direct conversion is fast but implementation is more complicated than panda's built-in method\n",
    "\n",
    "Overall converting data to these types provide the benefits for efficient storage, I/O time and providing convenient way of transferring data between Python and R."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c013e40e2d9040cd91207286d0a328254c2aff87275ac4a02e4e6d7d05ff1da1"
  },
  "kernelspec": {
   "display_name": "Python [conda env:.conda-525_2022]",
   "language": "python",
   "name": "conda-env-.conda-525_2022-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
