import pandas as pd


output_directory = "../data"
rerun = False


if rerun:
    df = pd.read_csv(f"{output_directory}/combined_data.csv",index_col=0, parse_dates=True)


get_ipython().run_cell_magic("time", "", """
if rerun:
    df.to_parquet(f"{output_directory}/combined_data.parquet")""")


get_ipython().run_cell_magic("time", "", """
if rerun:
    df.to_parquet(f"{output_directory}/combined_data_partition.parquet",partition_cols=['model'])""")


get_ipython().run_cell_magic("sh", "", """du -sh "../data/combined_data.csv"
du -sh "../data/combined_data.parquet"
du -sh "../data/combined_data_partition.parquet"""")


get_ipython().run_cell_magic("time", "", """
df = pd.read_parquet(f"{output_directory}/combined_data.parquet")
print(df["model"].value_counts())""")


get_ipython().run_line_magic("load_ext", " rpy2.ipython")


get_ipython().run_cell_magic("time", "", """%%R

suppressPackageStartupMessages(library(dplyr,quietly=TRUE))
output_directory <- "../data"
#df <- arrow::read_parquet(paste0(output_directory,"/","combined_data_partition.parquet"))
df <- arrow::open_dataset(paste0(output_directory,"/","combined_data_partition.parquet"), 
                          format="parquet", 
                          partitioning=c("model"))
df %>%
    group_by(model) %>%
    summarize(cnt=n()) %>%
    ungroup() %>%
    collect()""")
